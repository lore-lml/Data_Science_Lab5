{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lorenzo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   },
   "source": [
    "Implementazione TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "import string\n",
    "import re\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def __call__(self, document):\n",
    "        lemmas = []\n",
    "        regex = re.compile(\"[0-9]+\")\n",
    "        \n",
    "        for t in word_tokenize(document):\n",
    "            t = t.strip()\n",
    "            lemma = self.lemmatizer.lemmatize(t)\n",
    "            if lemma not in string.punctuation and 3 < len(lemma) < 16 and not regex.match(lemma):\n",
    "                lemmas.append(lemma)\n",
    "    \n",
    "        return lemmas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trovo tutte le directory dei documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "rel_path = \"data_sets/T-newsgroups/\"\n",
    "documents = [os.path.join(rel_path, d) for d in sorted(os.listdir(rel_path), key=int)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizzo tutte le parole dei documenti tramite il LemmaTokenizer eliminando le stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<4000x40684 sparse matrix of type '<class 'numpy.float64'>'\n\twith 357446 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 48
    }
   ],
   "source": [
    "stopwords = sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "lemmaTokenizer = LemmaTokenizer()\n",
    "# Trasforma le liste di token in numeri che vengono inseriti in una matrice di numpy float in modo da poterli analizzare\n",
    "vectorizer = TfidfVectorizer(input=\"filename\",tokenizer=lemmaTokenizer, stop_words=stopwords)\n",
    "tfidf_X = vectorizer.fit_transform(documents)\n",
    "tfidf_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PRINCIPAL COMPONENT ANALYSIS (PCA)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total variance explained: 0.86\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(4000, 2000)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 57
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=2000, random_state=42)\n",
    "svd_X = svd.fit_transform(tfidf_X)\n",
    "print(f\"Total variance explained: {np.sum(svd.explained_variance_ratio_):.2f}\")\n",
    "np.shape(svd_X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def generate_wordclouds(X, X_tfidf, k, word_positions):\n",
    "    \"\"\"Cluster X with K-means with the specified k, and generate one wordcloud per cluster.\n",
    "    :input X: numpy.array or numpy.matrix to cluster\n",
    "    :input X_tfidf: sparse matrix with TFIDF values\n",
    "    :input k: the k to be used in K-means\n",
    "    :input word_positions: dictionary with pairs as word index (in vocabulary) -> word\n",
    "    :return cluster_ids: set with the clusters ids\n",
    "    \"\"\"\n",
    "    model = KMeans(n_clusters=k, random_state=42, n_jobs=-1)\n",
    "    y_pred = model.fit_predict(X)\n",
    "    cluster_ids = set(y_pred)\n",
    "    top_count = 100\n",
    "    for cluster_id in cluster_ids:\n",
    "        # compute the total tfidf for each term in the cluster\n",
    "        tfidf = X_tfidf[y_pred == cluster_id]\n",
    "        tfidf_sum = np.sum(tfidf, axis=0) # numpy.matrix\n",
    "        tfidf_sum = np.asarray(tfidf_sum).reshape(-1) # numpy.array of shape(1, X.shape[1])\n",
    "        top_indices = tfidf_sum.argsort()[-top_count:]\n",
    "        \n",
    "        term_weights = {word_positions[idx]: tfidf_sum[idx] for idx in top_indices}\n",
    "        wc = WordCloud(width=1200, height=800, background_color=\"white\")\n",
    "        wordcloud = wc.generate_from_frequencies(term_weights)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        \n",
    "        ax.axis(\"off\")\n",
    "        fig.suptitle(f\"Cluster {cluster_id}\")\n",
    "    return cluster_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "word_positions = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "#cluster_ids = generate_wordclouds(svd_X, tfidf_X, 4, word_positions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "FP-Growth results on Cluster 0 with min support 0.3\n",
      "     support           itemsets\n",
      "4   0.649874            (space)\n",
      "2   0.619647           (writes)\n",
      "3   0.574307          (article)\n",
      "13  0.511335  (writes, article)\n",
      "5   0.380353             (like)\n",
      "8   0.360202             (also)\n",
      "9   0.345088             (much)\n",
      "12  0.345088    (space, writes)\n",
      "6   0.324937            (orbit)\n",
      "14  0.324937   (space, article)\n",
      "0   0.319899           (system)\n",
      "1   0.317380          (shuttle)\n",
      "7   0.317380             (year)\n",
      "11  0.304786            (think)\n",
      "10  0.302267             (time)\n",
      "FP-Growth results on Cluster 1 with min support 0.3\n",
      "     support                 itemsets\n",
      "0   0.669675                 (writes)\n",
      "1   0.617329                   (game)\n",
      "2   0.588448                (article)\n",
      "16  0.555957        (writes, article)\n",
      "12  0.509025                   (year)\n",
      "3   0.447653                   (last)\n",
      "4   0.440433                   (team)\n",
      "5   0.398917                  (think)\n",
      "15  0.391697           (writes, game)\n",
      "6   0.382671                   (like)\n",
      "13  0.380866                   (good)\n",
      "7   0.375451                   (time)\n",
      "8   0.366426               (baseball)\n",
      "22  0.357401           (writes, year)\n",
      "17  0.355596          (article, game)\n",
      "9   0.350181                 (player)\n",
      "10  0.335740                  (first)\n",
      "18  0.333935  (article, writes, game)\n",
      "20  0.328520             (last, year)\n",
      "11  0.312274                   (well)\n",
      "23  0.310469          (year, article)\n",
      "14  0.308664                   (know)\n",
      "19  0.303249           (writes, last)\n",
      "21  0.301444           (writes, team)\n",
      "FP-Growth results on Cluster 2 with min support 0.3\n",
      "     support                   itemsets\n",
      "0   0.721180                   (writes)\n",
      "1   0.674263                  (article)\n",
      "16  0.601877          (writes, article)\n",
      "2   0.565684                   (people)\n",
      "7   0.418231                    (think)\n",
      "14  0.416890                    (right)\n",
      "17  0.411528           (writes, people)\n",
      "8   0.388740                     (like)\n",
      "18  0.380697          (article, people)\n",
      "11  0.376676               (government)\n",
      "9   0.361930                     (time)\n",
      "13  0.348525                     (make)\n",
      "10  0.347185                    (thing)\n",
      "3   0.341823                     (even)\n",
      "19  0.332440  (writes, article, people)\n",
      "4   0.329759                     (know)\n",
      "5   0.317694                  (believe)\n",
      "20  0.316354            (writes, think)\n",
      "15  0.312332                     (also)\n",
      "6   0.306971                (reference)\n",
      "22  0.306971            (writes, right)\n",
      "21  0.305630           (think, article)\n",
      "12  0.300268                     (well)\n",
      "FP-Growth results on Cluster 3 with min support 0.3\n",
      "    support           itemsets\n",
      "0  0.522796           (writes)\n",
      "1  0.474164          (article)\n",
      "2  0.424663  (writes, article)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "model = KMeans(n_clusters=4, random_state=42, n_jobs=-1)\n",
    "y_pred = model.fit_predict(svd_X)\n",
    "cluster_ids2 = set(y_pred)\n",
    "min_support = 0.3\n",
    "dist_words = sorted([v for k,v in word_positions.items()])\n",
    "\n",
    "for id in cluster_ids2:\n",
    "    print(f\"FP-Growth results on Cluster {id} with min support {min_support}\")\n",
    "    \n",
    "    tfidf = tfidf_X[y_pred == id]\n",
    "    # to create a dataframe needs a matrix with just 0 (if absent) and 1 (if present)\n",
    "    tfidf[tfidf > 0] = 1\n",
    "    df = pd.DataFrame.sparse.from_spmatrix(tfidf, columns=dist_words)\n",
    "    fset = fpgrowth(df, min_support, use_colnames=True).sort_values(by='support', ascending=False)\n",
    "    print(fset)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}